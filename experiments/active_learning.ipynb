{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import softmax as softmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader.builder import build_dataset\n",
    "from experiment_setup import build_estimator\n",
    "from uncertainty_estimator.masks import build_masks, DEFAULT_MASKS\n",
    "from analysis.metrics import uq_ndcg\n",
    "\n",
    "from model.cnn import SimpleConv, MediumConv, StrongConv\n",
    "from model.trainer import Trainer, EnsembleTrainer\n",
    "from active_learning.al_trainer import ALTrainer\n",
    "from active_learning.sample_selector import EagerSampleSelector, StochasticSampleSelector\n",
    "\n",
    "# torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'use_cuda': True,\n",
    "    'seed': 1,\n",
    "    \n",
    "    'nn_runs': 100,\n",
    "    'patience': 5,\n",
    "    'dropout_uq': 0.5,\n",
    "    \n",
    "    'n_models': 10, \n",
    "    \n",
    "    # 'dataset': 'mnist',\n",
    "    'dataset': 'cifar_10',\n",
    "    \n",
    "    'model_runs': 10,   \n",
    "    \n",
    "    'al_iterations': 10,\n",
    "    'sampler_type': 'eager'\n",
    "    # 'sampler_type': 'stochastic'\n",
    "}\n",
    "\n",
    "\n",
    "model_setups = {\n",
    "    'mnist': {\n",
    "        'model_class': SimpleConv,\n",
    "        'train_samples': 5000,\n",
    "        'epochs': 5,\n",
    "        'batch_size': 32,\n",
    "        'log_interval': 10,\n",
    "        'lr': 1e-2,\n",
    "        'num_classes': 10,\n",
    "        'input_shape': (-1, 1, 28, 28),\n",
    "        'al_start': 300,\n",
    "        'al_step': 200,\n",
    "        'pool_size': 5_000\n",
    "    },\n",
    "    'cifar_10': {\n",
    "        'model_class': MediumConv,\n",
    "        'train_samples': 45_000,\n",
    "        'epochs': 50,\n",
    "        'batch_size': 256,\n",
    "        'log_interval': 150,\n",
    "        'lr': 1e-2,\n",
    "        'num_classes': 10,\n",
    "        'input_shape': (-1, 3, 32, 32),\n",
    "        'al_start': 10_000,\n",
    "        'al_step': 1000,\n",
    "        'pool_size': 25_000\n",
    "    }\n",
    "}\n",
    "\n",
    "config.update(model_setups[config['dataset']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = build_dataset(config['dataset'], val_size=10_000)\n",
    "x_set, y_set = dataset.dataset('train')\n",
    "x_val, y_val = dataset.dataset('val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale(images):\n",
    "    return (images - 128) / 128\n",
    "x_set = scale(x_set)\n",
    "x_val = scale(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_set = x_set.reshape(config['input_shape'])\n",
    "x_val = x_val.reshape(config['input_shape'])\n",
    "\n",
    "y_set = y_set.astype('long').reshape(-1)\n",
    "y_val = y_val.astype('long').reshape(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def al_evaluate(\n",
    "        model, estimator, x_train, y_train, x_val, y_val, x_pool):\n",
    "    \"\"\"Train \"\"\"\n",
    "    if config['sampler_type'] == 'eager':\n",
    "        sampler = EagerSampleSelector()\n",
    "    else:\n",
    "        sampler = StochasticSampleSelector()\n",
    "        \n",
    "    active_teacher = ALTrainer(\n",
    "        model, estimator, y_pool=y_pool.copy(), patience=3, update_size=200,\n",
    "        iterations=config['al_iterations'], verbose=False, sampler=sampler)\n",
    "    errors = active_teacher.train(\n",
    "        x_train.copy(), y_train.copy(), x_val.copy(), y_val.copy(), x_pool.copy())\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "errors = defaultdict(list) \n",
    "\n",
    "for i in range(config['model_runs']):\n",
    "    x_train, x_pool, y_train, y_pool= train_test_split(\n",
    "        x_set, y_set, train_size=config['al_start'], stratify=y_set)\n",
    "    x_pool, _, y_pool, _ = train_test_split(x_pool, y_pool, train_size=config['pool_size'])\n",
    "    masks = build_masks(DEFAULT_MASKS)\n",
    "\n",
    "    # Random estimator\n",
    "    print(f\"\\nrandom\\n\")\n",
    "    model = config['model_class'](num_classes=config['num_classes'])\n",
    "    trainer = Trainer(model, batch_size=config['batch_size'])\n",
    "    estimator = build_estimator('random', trainer)\n",
    "    model_errors = al_evaluate(trainer, estimator, x_train, y_train, x_val, y_val, x_pool)\n",
    "    errors['random'].append(model_errors)\n",
    "    \n",
    "    # # Ensemble\n",
    "    # print(f\"\\nensemble\\n\")\n",
    "    # ensemble = EnsembleTrainer(\n",
    "    #     config['model_class'], {'num_classes': config['num_classes']}, config['n_models'],\n",
    "    #     batch_size=config['batch_size'])\n",
    "    # estimator = build_estimator('bald_ensemble', ensemble, num_classes=config['num_classes'])\n",
    "    # model_errors = al_evaluate( ensemble, estimator, x_train, y_train, x_val, y_val, x_pool)\n",
    "    # errors['ensemble'].append(model_errors)\n",
    "\n",
    "    # Masks\n",
    "    for name, mask in masks.items():\n",
    "        print(f\"\\n{name}\\n\")\n",
    "        model = config['model_class'](num_classes=config['num_classes'])\n",
    "        trainer = Trainer(model, batch_size=config['batch_size'])\n",
    "        estimator = build_estimator(\n",
    "            'bald_masked', trainer, nn_runs=config['nn_runs'], dropout_mask=mask,\n",
    "            dropout_rate=config['dropout_uq'], num_classes=config['num_classes'])\n",
    "        \n",
    "        model_errors = al_evaluate(trainer, estimator, x_train, y_train, x_val, y_val, x_pool)\n",
    "        errors[name].append(model_errors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "for name, err_values in errors.items():\n",
    "    err_values = np.stack(err_values)\n",
    "    means = np.mean(err_values, axis=0)\n",
    "    stds = np.std(err_values, axis=0)\n",
    "    plt.plot(means, label=name)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(means)), means-stds, means+stds, alpha=.1)\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Step\")\n",
    "title = f\"Active learning with {config['al_start']} starting samples\"\n",
    "title += f\"and {config['al_step']} samples per step\"\n",
    "plt.title(title)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}